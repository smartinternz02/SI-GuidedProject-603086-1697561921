{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Vegetable_Images_2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp7ghEXjBh8c",
        "outputId": "0bb2ad48-983f-46be-8b77-6ec6ecbf0dca"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "from tensorflow.keras import models, layers, optimizers  # Add this import statement\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "4lDSmyRRIlIh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64  # You can adjust this based on your GPU memory\n",
        "CHANNELS = 3\n",
        "EPOCHS = 10\n",
        "CLASS_NAMES = ['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot',\n",
        "               'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']"
      ],
      "metadata": {
        "id": "hKRKvWL8Ivwm"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained MobileNetV2 model (include_top=False excludes the final dense layers)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))"
      ],
      "metadata": {
        "id": "1kxK383ZIuwC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "HIVCeQ9QJI2F"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(CLASS_NAMES), activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "R6Zy2RwjJOt2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-4),  # Adjust learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jye2uHcZKDkE",
        "outputId": "2697ab8d-66a5-4a03-e350-b7d16e0819b0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d_5  (None, 1280)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                81984     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 15)                975       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2340943 (8.93 MB)\n",
            "Trainable params: 82959 (324.06 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "\n",
        "# Data Augmentation\n",
        "train_data_augmentation = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "Q4Kz3hhnLCsY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "train_generator = train_data_augmentation.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Vegetable_Images_2/train',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASS_NAMES\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqxu-b6HLpiV",
        "outputId": "00fbd547-9d26-4fe4-8c4e-8b6bf7a56e36"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15020 images belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a directory for validation data similar to the training data\n",
        "val_folder_path = '/content/drive/MyDrive/Vegetable_Images_2/validation'\n",
        "\n",
        "# Validation Data Augmentation (you can adjust this based on your needs)\n",
        "val_data_augmentation = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create a validation data generator\n",
        "val_generator = val_data_augmentation.flow_from_directory(\n",
        "    val_folder_path,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'  # Assuming you have multiple classes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Q7u97OLw8E",
        "outputId": "d99a8dd2-8ff3-44ee-fb2a-1653f6df4eae"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-4NruAWSINb",
        "outputId": "051b141c-b32c-4e94-d735-26f8010b1230"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 1018s 4s/step - loss: 1.9314 - accuracy: 0.4001 - val_loss: 0.7224 - val_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 1016s 4s/step - loss: 0.8765 - accuracy: 0.7435 - val_loss: 0.2692 - val_accuracy: 0.9690 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 1028s 4s/step - loss: 0.5456 - accuracy: 0.8494 - val_loss: 0.1490 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 1000s 4s/step - loss: 0.4093 - accuracy: 0.8850 - val_loss: 0.1020 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 1020s 4s/step - loss: 0.3338 - accuracy: 0.9079 - val_loss: 0.0777 - val_accuracy: 0.9827 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 1028s 4s/step - loss: 0.2913 - accuracy: 0.9206 - val_loss: 0.0636 - val_accuracy: 0.9847 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 1021s 4s/step - loss: 0.2532 - accuracy: 0.9296 - val_loss: 0.0519 - val_accuracy: 0.9880 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 1023s 4s/step - loss: 0.2176 - accuracy: 0.9421 - val_loss: 0.0458 - val_accuracy: 0.9883 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 1014s 4s/step - loss: 0.1975 - accuracy: 0.9459 - val_loss: 0.0394 - val_accuracy: 0.9890 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 1011s 4s/step - loss: 0.1839 - accuracy: 0.9485 - val_loss: 0.0359 - val_accuracy: 0.9907 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Vegetable_Images_2/vegetable_model.h5')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_data_augmentation = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_data_augmentation.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Vegetable_Images_2/test',\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASS_NAMES\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_acc * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVKxY5lzC1M7",
        "outputId": "c6f39b8e-0cc5-442f-e3c8-50ea9020d7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 15 classes.\n",
            "47/47 [==============================] - 134s 3s/step - loss: 0.0550 - accuracy: 0.9870\n",
            "Test Accuracy: 98.70%\n"
          ]
        }
      ]
    }
  ]
}